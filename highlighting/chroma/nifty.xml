<lexer>
    <config>
        <name>Nifty</name>
        <alias>nifty</alias>
        <filename>*.nifty</filename>
        <mime_type>text/nifty</mime_type>
    </config>
    <rules>
        <state name="string">
            <rule pattern="\\(x[a-fA-F0-9]{2}|u[a-fA-F0-9]{4}|U[a-fA-F0-9]{6}|[nr\\t\&#39;&#34;])">
                <token type="LiteralStringEscape"/>
            </rule>
            <rule pattern="[^\\&#34;\n]+">
                <token type="LiteralString"/>
            </rule>
            <rule pattern="&#34;">
                <token type="LiteralString"/>
                <pop depth="1"/>
            </rule>
        </state>
        <state name="root">
            <rule pattern="\n">
                <token type="TextWhitespace"/>
            </rule>
            <rule pattern="\s+">
                <token type="TextWhitespace"/>
            </rule>
            <rule pattern="//.*?\n">
                <token type="CommentSingle"/>
            </rule>
            <rule pattern="/[*].*?[*]/">
                <token type="CommentMultiline"/>
            </rule>
            <rule pattern="/[-].*?[-]/">
                <token type="CommentMultiline"/>
            </rule>
            <rule pattern="(if|else|elif|while|until|for|return|when|break|continue|impl|constimpl|endimpl|in|defer|defer_err|restrict|goto|try)\b">
                <token type="Keyword"/>
            </rule>
            <rule pattern="(let|val|const|fn|md|type)\b">
                <token type="Keyword"/>
            </rule>
            <rule pattern="(use|using|as|extern|package|api)\b">
                <token type="Keyword"/>
            </rule>
            <rule pattern="(cast|recast|auto_cast|type_of|typeid_of|typeinfo_of|type_from|size_of|name_of|align_of|emit)\b">
                <token type="KeywordReserved"/>
            </rule>
            <rule pattern="(new|delete)\b">
                <token type="Keyword"/>
            </rule>
            <rule pattern="(null|undefined|unused|true|false)\b">
                <token type="KeywordConstant"/>
            </rule>
            <rule pattern="(struct|enum|behavior|does)\b">
                <token type="Keyword"/>
            </rule>
            <rule pattern="(bool|b8|b16|b32|b64|char|string|cstring|int|uint|uintptr|float|double|s8|s16|s32|s64|s128|u8|u16|u32|u64|u128|f16|f32|f64|f128|void|typeid|rawptr)\b">
                <token type="KeywordType"/>
            </rule>
            <rule pattern="(Self)\b">
                <token type="KeywordType"/>
            </rule>
            <rule pattern="(assert|assert_db|panic)\b">
                <token type="KeywordReserved"/>
            </rule>
            <rule pattern="0x[0-9a-fA-F]+\.[0-9a-fA-F]+([pP][\-+]?[0-9a-fA-F]+)?">
                <token type="LiteralNumberFloat"/>
            </rule>
            <rule pattern="0x[0-9a-fA-F]+\.?[pP][\-+]?[0-9a-fA-F]+">
                <token type="LiteralNumberFloat"/>
            </rule>
            <rule pattern="[0-9]+\.[0-9]+([eE][-+]?[0-9]+)?">
                <token type="LiteralNumberFloat"/>
            </rule>
            <rule pattern="[0-9]+\.?[eE][-+]?[0-9]+">
                <token type="LiteralNumberFloat"/>
            </rule>
            <rule pattern="0b(?:_?[01])+">
                <token type="LiteralNumberBin"/>
            </rule>
            <rule pattern="0o(?:_?[0-7])+">
                <token type="LiteralNumberOct"/>
            </rule>
            <rule pattern="0x(?:_?[0-9a-fA-F])+">
                <token type="LiteralNumberHex"/>
            </rule>
            <rule pattern="(?:_?[0-9])+">
                <token type="LiteralNumberInteger"/>
            </rule>
            <rule pattern="#[a-zA-Z_]\w*">
                <token type="NameBuiltin"/>
            </rule>
            <rule pattern="[a-zA-Z_]\w*">
                <token type="Name"/>
            </rule>
            <rule pattern="\&#39;\\\&#39;\&#39;">
                <token type="LiteralStringEscape"/>
            </rule>
            <rule pattern="\&#39;\\(|x[a-fA-F0-9]{2}|u[a-fA-F0-9]{4}|U[a-fA-F0-9]{6}|[nr\\t\&#39;&#34;])\&#39;">
                <token type="LiteralStringEscape"/>
            </rule>
            <rule pattern="\&#39;[^\\\&#39;]\&#39;">
                <token type="LiteralString"/>
            </rule>
            <rule pattern="[+%=&gt;&lt;|^!?/\-*&amp;~:]">
                <token type="Operator"/>
            </rule>
            <rule pattern="[{}()\[\],.;]">
                <token type="Punctuation"/>
            </rule>
        </state>
    </rules>
</lexer>